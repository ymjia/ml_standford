---
title: summary
header-includes:
  - \usepackage{cleveref}
  - \usepackage{asmmath}
author: jiayanming
---

## 目标函数Hypothesis
当遇到较复杂的问题时，我们希望通过已有的数据总结规律，进而利用此规律对新的数据作出判断。例如我们想对当前地区的房子进行估价，房子的价值与其一些固有特征有关，如面积，户型，通勤等等。即，对于一个代表房子特征的向量$m^{(i)} = [size, layout, commute, ...]$，其价值是 $p^{(i)}$。

我们的目标是找到一个函数映射来近似表示这一规律，由$m^{(i)}$映射到$p^{(i)} = h_{\theta}(m^{(i)})$，其中$\theta$与特征一一对应，将其理解为每一个特征对最终结果的贡献程度（权重），比如对房价而言，面积对最终价格的影响与户型对最终价格的影响程度不同。

为此，我们对数据集进行简单的分析，然后假定一个目标函数形式，如：
$h_{\theta}(m^{(i)}) = \theta_0 + \theta_1 * m^{(i)}_1 + \theta_2 * (m^{(i)}_2)^2 + ...$
其中，上标(i)是训练集元素的id，下标是训练向量中的元素id。

利用已有数据（训练集）对函数进行“训练”，训练目标是：获得一组参数$\theta = [\theta_1, \theta_2, ..., \theta_n]$，使目标函数的输出结果尽可能“符合”训练集，然后可利用得到的$\theta$代入到目标函数 $h_{\theta}$对新数据进行预测。

## 损失函数Cost Function
有了目标函数后，为了找到最优的参数，我们需要对目标函数与训练集是否“符合”进行评估，显然，对于不同的 $\theta$ ，目标函数在训练集上的表现不相同，为此引入一个关于 $\theta$ 的函数：损失函数$J(\theta)$，用来表征目标函数$h_{\theta}(m^{(i)})$的性能。对于训练集中的训练数据，利用损失函数评估当前参数下目标函数的性能。此时，我们训练的目的可以更明确的表示为：对损失函数做优化，寻找令损失函数取得最小值的$\theta$。

## 梯度下降法 Gradient descent
由于损失函数有不同的类型，可能是线性的也可能是非线性的，对其进行优化有可能很复杂，为此我们引入一种迭代优化方法，使其能够对大部分损失函数有较好的优化结果，这一方法叫作梯度下降法。

我们用贪心迭代的方式获取损失函数$J(\theta)$的极值点，步骤如下：

1. 给定一个初始化参数值 $\theta^{(0)} = [\theta_0, \theta_1, ..., \theta_n]$，对应的损失函数值是$J(\theta_0)$

2. 在局部范围内使用贪心策略改变$\theta = \theta + \Delta\theta$，使得$J(\theta)$减小

3. 迭代改变$\theta$，直到$J(\theta)$值收敛。

以上过程中，存在两个问题：

1. 迭代过程如何收敛。

   通过“精心挑选”损失函数的定义形式，我们可以保证损失函数是一个凸函数，此时，通过不断迭代，可以保证收敛到函数的最值。

2. 如何确定$\Delta\theta$使得$J(\theta)$值在每次迭代中变小。
   对于一个可导函数$f(x)$，我们在求解其极大/极小值时，通常会对函数进行求导得到$f'(x)$，然后取其导数为0的点即为极值点。类似的，根据函数梯度的定义，函数 $J(\theta)$ 在 $\theta$ 点的梯度方向为函数值增加最快的方向，因此我们取
$$\Delta\theta = -\lambda * grad(J(\theta))$$
其中 $grad(J)$ 表示函数 $J$ 在 $\theta$ 的梯度，$\lambda$ 是迭代步长。在每次迭代中，$J(\theta)$ 沿其梯度的反方向移动一小段距离，在 $\lambda$ 取值合适的前提下，因为损失函数 $J(\theta)$ 是凸函数，我们可以通过足够的迭代次数，找到使 $J(\theta)$ 取得最小值的 $\theta$ 。

根据以上步骤，损失函数$J(\theta)$的值沿其梯度的反方向逐步下降，所以此方法称为梯度下降法。接下来我们在具体的机器学习算法中，观察
* 目标函数
* 损失函数
* 梯度下降法
是如何解决实际问题的。

## 线性回归(拟合问题) Linear Regression
问题描述：
当我们要解决的问题是由输入$x$ 映射到一个连续区间内的值$y$时，可以考虑使用线性回归法。


1. 目标函数
$$h_{\theta}(x) = \theta_0 + \theta_1x_1 + \theta_2x2 + ... + \theta_nx_n$$
其中$x_i \in R$是输入用例的特征，$h_{\theta}(x)$是关于$x \in R^n$的线性函数，因此此方法称作线性回归法（暂时将“回归”理解为：由离散的数据点回归为连续的函数）。

2. 损失函数
对于每个训练数据$(x^{(i)}, y^{(i)})$，我们利用目标函数的输出$h_{\theta}(x^{(i)})$与数据中的Ground Truth $y^{(i)}$的距离来表示预测的损失，对于$m$个训练数据取其均值，即$$J(\theta) = \frac{1}{2m}\sum_i^m(h_{\theta}(x^{(i)}) - y^{(i)})^2$$
其中取均值时的$2m$是为了与求梯度时平方项导数2抵消。

3. 梯度下降法
对于$J(\theta) \theta \in \R^n$其梯度即$J$对各分量$\theta_i (i = 1, 2, ..., n)$的偏导数构成的向量：

$$ grad(J(\theta)) = \begin{pmatrix}\\
\frac{\partial J(\theta)}{\partial\theta_0}\\
\frac{\partial J(\theta)}{\partial\theta_1}\\
\vdots\\
\frac{\partial J(\theta)}{\partial\theta_n}\\
\end{pmatrix}
$$

因此，线性回归的梯度下降法迭代公式为：
$$\theta = \theta - \lambda * grad(J(\theta))\\
= \begin{pmatrix}\\
\theta_0 \\ \theta_1 \\ \vdots \\ \theta_n\\
\end{pmatrix} - \lambda \begin{pmatrix}\\
\frac{\partial J(\theta)}{\partial\theta_0}\\
\frac{\partial J(\theta)}{\partial\theta_1}\\
\vdots\\
\frac{\partial J(\theta)}{\partial\theta_n}\\
\end{pmatrix}
$$

其中，根据简单的偏导数公式，
$$\frac{\partial J(\theta)}{\partial\theta_i} = \frac{1}{m} \sum_i^m (h_{\theta}(x) - y)x_i$$

## 逻辑回归(分类问题) Logistic Regression
线性回归可以应用于输出值$y$是连续区间的问题，对于输出值非连续的问题，我们使用称为逻辑回归的方法。这一方法也是神经网络的基础。

所谓输出非连续，也就是常见的分类问题，比如判断一封邮件是不是垃圾邮件，一条评论是否是不和谐的问题，又或更复杂一些，图片里面的动物是哪种动物。

0. 线性回归不适用
分类问题一般不是线性问题，如下图，要区分o和x两类点：

1. 目标函数
   我们暂时只考虑输出有两类的分类问题，再扩展到多类问题

   对于只有两类的分类问题，其输出值为0或1。即训练数据$(x^{(i)}, y^{(i)})$ 中 $y^{(i)}$的取值为0或1，因此我们自然希望目标函数的值域也是集合{0, 1}，但值域仅为0和1的函数比较难找，且在考虑接下来损失函数的定义与梯度的问题时，如果输出是离散的，梯度下降法的应用也会有困难，所以这样采用一种策略：

   令目标函数$h_\theta(x)$的值域是区间[0, 1]，当$h_\theta(x)<0.5$时，认为输出为0，当$h_\theta(x) >= 0.5$时，认为输出为1。

   这样的理解也为分类问题增加了一个较重要的性质：概率。比如这封邮件有多大概率是垃圾邮件，此时对于不同的目标函数值，也可以进一步将其理解为一个概率，比如$h_\theta(x) = 0.3$，那么认为有30%的概率是1，70%的概率是0。

   那么为了让函数的值域区间是[0, 1]，我们引入一个具有很多优秀性质的函数：
   s型函数(sigmoid function)$$g(z) = \frac{1}{1 + e^{-z}}$$此函数的形态如下图：

   那么对于目标函数，我们仍然将输入的属性$x$与其权重$\theta$线性组合$$z = \theta^Tx$$

   然后将组合的值通过sigmoid function映射到区间(0, 1):
$$h_\theta(x) = g(z) = g(\theta^Tx)\\
= \frac{1}{1 + e^{-\theta^Tx}}$$

2. 损失函数

在线性回归中，损失函数定义的是目标函数的预测值($h_\theta(x)$)和真值(y)之间的距离。在逻辑回归中，我们使用类似的意义定义损失函数，但不能直接套用线性回归中的形式，因为在逻辑回归处理的分类问题中，离散的$y$值分布促使我们使用更合理的sigmoid函数来定义目标函数$h_\theta(x)$，这一形式和离散的$y$值会使得上述形式的损失函数成为非凸函数。

例如，对于下图所示数据集，坐标轴代表数据的两个属性($Property_{p1}, Property_{p2}$)，+/o代表对应的分类1/0($y$)

对于不同的$\theta$值 $(Weight_{p1}, Weight_{p2})$，损失函数$J(\theta) = \frac{1}{2m}\sum_i^m(h_{\theta}(x^{(i)}) - y^{(i)})^2$如下图。


为了损失函数能够更合理的表征目标函数预测值$h_\theta(x^{(i)})$与真值$y^J{(i)}$的差别，我们采取分段函数的方式，对不同的$y$值，有不同的损失函数形式：
$$h_\theta(x) = \begin{cases}
-log(1 - h_\theta(x)), y = 0\\
-log(h_\theta(x)),     y = 1\\
\end{cases}\\
$$

上述公式表示了，
* 当真值为0时，$h_\theta(x)$越接近0，损失越小，当$h_\theta(x)$接近1时，损失接近$+\infty$
* 当真值为1时，$h_\theta(x)$越接近1，损失越小，当$h_\theta(x)$接近0时，损失接近$+\infty$

将分段函数整理为完整的公式为：
$$h_\theta(x) = y * (-log(h_\theta(x))) + (1 - y) * (-log(1 - h_\theta(x)))$$

3. 梯度下降法

有了损失函数的定义后，我们应用梯度下降法求损失函数的最小值。与线性回归类似，损失函数的梯度$grad(J)$的分量即为损失函数 $J(\theta)$ 对 $\theta$ 的每个分量 $\theta_j, j = 1, 2, ..., n$ 求偏导数：
$$\frac{\partial J(\theta)}{\partial \theta_j} = \frac{1}{m}\sum_i^m(h_\theta(x^{(i)}) - y^{(i)}) x_j^{(i)}$$

在实现过程中，将所有输入数据计为矩阵形式：
$$X = \begin{pmatrix}\\
x^{(0)T}\\
x^{(1)T}\\
\vdots\\
x^{(m)T}\\
\end{pmatrix}\\
$$

向量化版本的梯度计算为：
$$grad(J(\theta)) = X^T(h_\theta(X) - Y)$$

## 正则化 Regularization
1. 过拟合与欠拟合
机器学习的过程，实际是使用目标函数去拟合数据集的过程，那么在拟合过程中，会出现两类问题


## 神经网络 Neral Network

## 支持向量机 Support Vector Machine

## 聚类问题
